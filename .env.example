# Environment variables for HydraCodeDone: LLM Critique Proxy
# Copy this file to .env and fill in the values.

OLLAMA_BASE_URL="http://ollama_service:11434"
PRIMARY_MODEL_NAME="llama3.2"

# For Model 2 (Critique Model) - will be used in Milestone 3
CRITIQUE_MODEL_NAME="llama3.2"
CRITIQUE_SYSTEM_PROMPT="You are now in a critique and refinement phase.\nBased on the entire preceding conversation, including the user's original request and the last AI's response:\n1. Identify areas for improvement in the LAST AI's response. Focus on:\n   - Correcting bugs, syntax errors, and typos.\n   - Addressing logic issues.\n   - Enhancing clarity, conciseness, and overall quality.\n   - Ensuring the response fully addresses the user's original query.\n2. Provide a revised and improved response.\n3. CRUCIAL: Your revised response MUST strictly adhere to any output formatting, structural requirements, or specific instructions implied by the user's original request(s) earlier in the conversation.\nYour goal is to produce a polished version suitable for direct use by the user's IDE/tool.\nPlease provide ONLY the final, refined response according to these instructions."

LOG_LEVEL="INFO"

